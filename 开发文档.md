## 开发文档

### 添加一个页面

1. 添加一个menu, 绑定view/person/person.vue 

   ```
   10	2024-04-15 08:53:12.692	2024-04-15 08:53:12.692		0	0	person	person	1	view/person/person.vue	4		0	0	个人信息	message	0
   ```

2. 绑定 角色 -menu 表  子路由 注意 **parent_id**
3. 开发 view/person/person.vue  （发送请求要注意casbin 权限

注意：navicat修改数据库表后，有时候不能及时更新，关闭数据库，后端，重新打开

**后端添加一个接口**

0. Router(router/system/sys_game.go)   -> Controller(GameApi: api/v1/system/sys_game.go)  -> Service(GameService :service/system/sys_game.go) 

1. 路由层：router.go ,InitUserRouter添加一个请求接口
   baseRouter.POST("register", baseApi.RegisterUser)
2. Controller层：编写Api  （根据需求 添加修改model (RegisterTables 添加自动迁移)，和调用service层 与数据库交互）



### BUG

【发现BUG】刷新会导致token丢失，仅与登出loginout有关。触发：点击登出后再次登录。但再登出后登录又会修复。
		暂时解决：手动点击再登出后再登录

【文件上传BUG】 <el-upload  :action="`${path}/file/upload`" 引起的，上传失败，后端apifox正常。
原因：浏览器同源跨域问题，也可能el-upload  :action的问题。 
尝试过：配置了前端代理，似乎无效。
**待解决**：后续尝试不用el-upload  :action，直接axios请求8889后端。    理论上运行环境，没有跨域问题就会是正常的。
**已解决**：文件上传功能修复，解决：不能直接组件和axios，要通过utils/request的拦截器，采用自定义api调用

### 文件上传和下载地址
请求：import.meta.env.VITE_BASE_API + /file/upload
下载：import.meta.env.VITE_BASE_API + /file/...

### 支持markdown:

pnpm install markdown-it      
```vue
import MarkdownIt from 'markdown-it'; 
const md = new MarkdownIt();
 
 <div v-html="md.render(challengeInfo.queDescribe)" />
```



### 引入图表：
❯ pnpm install echarts



### K3S管理

```shell
# 查看所有的 pods：
kubectl get pods
# 查看所有的 services：
kubectl get services
# 查看一个特定 pod/service 的详细信息
kubectl describe  pod/service <pod_name>/<service_name>
# 删除
kubectl delete pod/service <pod_name>/<service_name>

# 查看日志
kubectl logs <pod_name>

# 查看集群中的所有节点（是 Pod 真正运行的主机）
kubectl get nodes
# 获取所有 Pods 的镜像 
kubectl get pods -n <namespace> -o jsonpath="{range .items[*]}{'\n'}{.metadata.name}:{range .spec.containers[*]}{.image}{', '}{end}{end}"

kubectl get pods -n default -o jsonpath="{range .items[*]}{'\n'}{.metadata.name}:{range .spec.containers[*]}{.image}{', '}{end}{end}"

# 获取特定 Deployment 的镜像
kubectl get deployment <deployment-name> -n <namespace> -o jsonpath="{.spec.template.spec.containers[*].image}"
```

场景：ctf比赛中每个用户通过这个函数开启一个靶机

### 每个用户开启容器：

1. **使用唯一的标签**：在你的代码中，所有的 Deployment 和 Service 都使用了相同的标签 "app": "N8U-app"。这可能会导致 Service 选择错误的 Pod。你应该为每个用户生成唯一的标签。
2. **清理资源**：在比赛结束后，你应该清理不再需要的 Deployment 和 Service。你可以在创建它们时添加一个标签，然后在比赛结束后删除所有带有这个标签的资源。
3. **错误处理**：你的代码中缺少了一些错误处理。例如，如果创建 Deployment 或 Service 失败，你应该删除已经创建的资源。
4. **等待 Pod 变为 Running 状态**：你的代码中有一个注释 "等待 Pod 状态变为 Running"，但是没有实现这个功能。你应该添加一个循环，等待 Pod 的状态变为 Running。
5. **使用 Deployment 可能不是最佳选择**：如果每个用户只需要一个 Pod，那么直接创建 Pod 可能会更简单。Deployment 主要用于需要多个副本的应用，或者需要滚动更新的应用。
6. **暴露服务**：你使用了 NodePort 类型的 Service 来暴露服务，这意味着服务会在每个节点的一个特定端口上暴露。这可能会导致端口冲突，如果你有很多用户，可能会耗尽可用的端口。你可能需要使用 LoadBalancer 类型的 Service，或者使用 Ingress 来暴露服务。但是这取决于你的 Kubernetes 集群的环境。
7. **资源限制**：你没有为 Pod 设置资源限制。在 CTF 比赛中，如果不设置资源限制，恶意用户可能会消耗大量的资源。你应该为每个 Pod 设置 CPU 和内存的限制。

pods 会根据负载均衡自动运行在 主控制节点或 从节点 ：
访问方式 任意节点ip+pod通过service暴露的端口 （ Pod 在 slave 节点上运行，你仍然可以通过 master 节点的 IP 地址和 NodePort 来访问 Service，Kubernetes 会自动将请求路由到正确的节点上）

在 Kubernetes 中，当你发送删除 Pod 的请求时，Pod 不会立即被删除。相反，它会首先进入 "Terminating" 状态，然后 Kubernetes 会尝试优雅地关闭 Pod 中的所有容器。这个过程可能需要一些时间，具体取决于你的容器如何处理 SIGTERM 信号。
